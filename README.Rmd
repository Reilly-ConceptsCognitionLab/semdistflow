---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# semdistflow

<!-- badges: start -->
<!-- badges: end -->

## Overview

‘semdistflow’ transforms any user-specified text into sequential bigrams (e.g. ‘The dog drinks the milk’ to dog-drink, drink-milk, etc.).  The package can compute metrics of semantic distance for each bigram.  Users have many options for parameterizing semantic distance and tailoring their analyses to their own unique constraints (e.g., omitting stopwords, lemmatizing tokens, dimensionality of word embeddings).

## Installation

You can install the development version of semdistflow from [GitHub](https://github.com/) with:

``` {r }
# install.packages("devtools")
devtools::install_github("Reilly-ConceptsCognitionLab/semdistflow")
```

## Example of Cleaning Function

This is a basic example which shows you how the cleanme function works:

```{r example, message=FALSE}
library(semdistflow)
library(tidyverse)

doc_id <- "fox"
doc_text <- "The quick brown fox jumps over the lazy dog."
fox_text <-as.data.frame(cbind(doc_id,doc_text))
fox_text
```

```{r clean}
fox_clean <- cleanme(fox_text)
fox_clean
```

## Example of Semantic Distance Function

This is a basic example which shows you how the cleanme function works:

```{r token}
fox_token <-fox_clean %>%
  group_by(doc_id, doc_text) %>%
  tidytext::unnest_tokens(word, doc_clean, drop=F)

fox_token$lemma<- textstem::lemmatize_words(fox_token$word)


fox_token
```



```{r semdist}
fox_dist <-  bigram_cos_sim(targetdf = fox_token, lookupdb = semdist15, colname1 = lemma, colname2 = word, flipped = T)

fox_dist
```

```{r plot}
ggplot(fox_dist, aes(x=as.numeric(row.names(fox_dist)), y=flipped_cosine.dist)) +  geom_line(color="#02401BD9", size= 1) + theme_classic() + xlab(NULL) + ylab(NULL)  + geom_label(aes(label=pair), size=3, data=fox_dist)  
```
